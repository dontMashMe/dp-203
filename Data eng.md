# Introduction to Data Engineering
Note taking document for the Azure Data Engineer certificate.

## What is data engineering?
The data engineer will often work with multiple types of data to perform many operations using many scripting or coding languages that are appropriate to their individual organization.

Types of data: 

| Structured | Semi-structured | Unstructured | 
| ----------- | ----------- | ----------- | 
| Primarily comes from table-based source systems such as a relational database or from a flat file such as a comma separated (CSV) file.| Data such as JSON. May require flattening. Once flattened, it doesn't have to fit neatly into a table structure. |Includes data stored as key-value pairs. Doesn't adhere to standard relational models/ structures such as PDF, Word etc.

### Data operations
DE's main tasks:
* data integration
* data transformation
* data consolidation

#### Data integration
Involves establishing links between operational and analytical services and data sources to enable secure & reliable access to data. 
For example, business might rely on data coming from multiple different systems, and it is DE's job to establish links so that the data can be extracted from all of these systems. 

#### Data transformations
Operational data usually needs to be transformed into suitable structure and format for analysis, often as part of ETL process, though increasingly a variation ELT is used where data is quickly ingested into a data lake, and then "big data" processing techniques are applied to transform it.

#### Data consolidation
Process of combining data from multiple sources into a consistent structure - usually to support analytics and reporting.

### Tools
* SQL
* Python 
* Other languages, depending on the environment
    * Scala, R, Java, .NET

## Important concepts
There are some core concepts with which data engineers should be familiar. These concepts underpin many of the workloads that data engineers must implement and support.


### Operational and analytical data
*Operational* data is (usually) transactional data that is generated and stored by applications, often in relational database. *Analytical* data is data which is optimized for analysing and reporting, often in a data warehouse.

One of the **core responsibilities** of a data engineer is to design, implement, and manage solutions that integrate operational and analytical data sources or extract operational data from multiple systems, transform it into appropriate structures for analytics, and load it into an analytical data store (usually referred to as ETL solutions).

### Streaming data
Refers to perpetual sources of data that generate data values in real-time (often IoT devices and social media feeds)

DE need to implement solutions that capture real-time stream of data and ingest them into analytical data systems, often combining data which is streamed and data which is processed in batches.

### Data pipelines
Used to orchestrate activities that transfer and transform data. 
Primary way of implementing repeatable ETL solutions that can be triggered based on a condition, or scheduled.

### Data lakes
Storage repository which holds data in raw, native format.
They are optimized for scaling massive volumes of data. 

The data usually comes from multiple heterogenous sourcesl, and my be structured, semi-structured or unstructured.

The idea with data lake is to store everything in its original, untransformed state. 

### Data warehouse
Centralized repository of integrated data from one or more disparate sources. They store current and historical data in relational tables that are organized into schemas which are optimized for analytical queries.

DE's are responsible for designing and implementing Data warehouses, and managing regular loads into the tables.

### Apache Spark
Parallel processing framework that takes advantage of in-memory processing (this just means it doesnt have to load the stuff from the disk all the time) 

## Data engineering in Microsoft Azure.
![alt text](3-data-engineering-azure-1.png)

The diagram represents the flow of data of a typical enterprise solutionl.

Operational data is generated by application and devices.

This operational data must be captured, ingested, and consolidated into analytical stores; from where it can be modeled and visualized in reports and dashboards. These tasks represent the core area of responsibility for the data engineer. The core Azure technologies used to implement data engineering workloads include: